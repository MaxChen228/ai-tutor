import os
import openai
import datetime
import random
import json
import psycopg2 # å¼•å…¥ PostgreSQL é©…å‹•
import psycopg2.extras # å¼•å…¥ç”¨æ–¼å­—å…¸ cursor çš„é¡å¤–åŠŸèƒ½
from prompt_assets import EXAMPLE_SENTENCE_BANK # ã€æ–°å¢ã€‘å¼•å…¥æˆ‘å€‘çš„ã€Œå½ˆè—¥åº«ã€

# --- æ ¸å¿ƒå­¸ç¿’åƒæ•¸ (å¯èª¿æ•´) ---
# é€™å…©å€‹åƒæ•¸ç¾åœ¨ä¸»è¦ç”¨æ–¼æœ¬åœ°ç«¯æ¸¬è©¦ï¼Œç·šä¸Šæœå‹™ç”± App å‚³å…¥ç‚ºæº–
SESSION_SIZE = 2
REVIEW_RATIO = 0.5
MONITOR_MODE = True

# --- è³‡æ–™åº«è¨­å®šèˆ‡ç®¡ç† ---
DATABASE_URL = os.environ.get('DATABASE_URL')

try:
    with open("ç¿»è­¯å¥å‹.md", "r", encoding="utf-8") as f:
        translation_patterns = f.read()
except FileNotFoundError:
    print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° `ç¿»è­¯å¥å‹.md` æª”æ¡ˆã€‚è«‹ç¢ºä¿æª”æ¡ˆèˆ‡ä¸»ç¨‹å¼åœ¨åŒä¸€å€‹è³‡æ–™å¤¾ã€‚")
    translation_patterns = "ï¼ˆæ–‡æ³•æ›¸è®€å–å¤±æ•—ï¼‰"

def get_db_connection():
    """å»ºç«‹ä¸¦å›å‚³ä¸€å€‹æ–°çš„ PostgreSQL è³‡æ–™åº«é€£ç·šã€‚"""
    try:
        conn = psycopg2.connect(DATABASE_URL)
        return conn
    except psycopg2.OperationalError as e:
        print(f"è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿æ‚¨å·²åœ¨ Render ç’°å¢ƒè®Šæ•¸ä¸­æ­£ç¢ºè¨­å®šäº† 'DATABASE_URL'ã€‚")
        exit()

def init_db():
    """
    ã€v5.12 æ”¹é€ ã€‘: ç‚º knowledge_points è¡¨æ ¼æ–°å¢ key_point_summary æ¬„ä½ã€‚
    """
    conn = get_db_connection()
    with conn.cursor() as cursor:
        print("æ­£åœ¨æª¢æŸ¥ä¸¦åˆå§‹åŒ– PostgreSQL è³‡æ–™åº«...")

        cursor.execute("""
        CREATE TABLE IF NOT EXISTS learning_events (
            id SERIAL PRIMARY KEY,
            question_type TEXT NOT NULL,
            source_mistake_id INTEGER,
            chinese_sentence TEXT NOT NULL,
            intended_pattern TEXT,
            user_answer TEXT,
            is_correct BOOLEAN NOT NULL,
            response_time REAL,
            self_assessment_score INTEGER,
            error_category TEXT,
            error_subcategory TEXT,
            ai_feedback_json TEXT,
            difficulty REAL,
            stability REAL,
            next_review_date DATE,
            timestamp TIMESTAMPTZ NOT NULL
        );
        """)
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS knowledge_points (
            id SERIAL PRIMARY KEY,
            category TEXT NOT NULL,
            subcategory TEXT NOT NULL,
            correct_phrase TEXT NOT NULL UNIQUE,
            explanation TEXT,
            user_context_sentence TEXT,
            incorrect_phrase_in_context TEXT,
            key_point_summary TEXT,
            mastery_level REAL DEFAULT 0.0,
            mistake_count INTEGER DEFAULT 0,
            correct_count INTEGER DEFAULT 0,
            last_reviewed_on TIMESTAMPTZ,
            next_review_date DATE
        );
        """)
    conn.commit()
    conn.close()
    print("è³‡æ–™åº«è¡¨æ ¼å·²æº–å‚™å°±ç·’ã€‚")

def add_mistake(question_data, user_answer, feedback_data, exclude_phrase=None):
    """
    ã€v5.12 æ”¹é€ ã€‘: è¨˜éŒ„éŒ¯èª¤æ™‚ï¼Œå°‡ key_point_summary ä¸€ä½µå­˜å…¥è³‡æ–™åº«ã€‚
    """
    conn = get_db_connection()
    with conn.cursor() as cursor:
        is_correct = feedback_data.get('is_generally_correct', False)
        feedback_json = json.dumps(feedback_data, ensure_ascii=False, indent=2)
        chinese = question_data.get('new_sentence', 'ï¼ˆé¡Œç›®æ–‡å­—éºå¤±ï¼‰')
        q_type = question_data.get('type', 'new')
        source_id = question_data.get('original_mistake_id')
        
        primary_error_category = "ç¿»è­¯æ­£ç¢º"
        primary_error_subcategory = "ç„¡"
        error_analysis = feedback_data.get('error_analysis', [])
        if error_analysis:
            major_errors = [e for e in error_analysis if e.get('severity') == 'major']
            if major_errors:
                primary_error_category = major_errors[0].get('error_type', 'åˆ†é¡éŒ¯èª¤')
                primary_error_subcategory = major_errors[0].get('error_subtype', 'å­åˆ†é¡éŒ¯èª¤')
            else:
                primary_error_category = error_analysis[0].get('error_type', 'åˆ†é¡éŒ¯èª¤')
                primary_error_subcategory = error_analysis[0].get('error_subtype', 'å­åˆ†é¡éŒ¯èª¤')

        cursor.execute(
            """
            INSERT INTO learning_events 
            (question_type, source_mistake_id, chinese_sentence, user_answer, is_correct, 
            error_category, error_subcategory, ai_feedback_json, timestamp) 
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """,
            (q_type, source_id, chinese, user_answer, is_correct, 
            primary_error_category, primary_error_subcategory, 
            feedback_json, datetime.datetime.now(datetime.timezone.utc))
        )
        
        if not is_correct and error_analysis:
            print("\næ­£åœ¨æ›´æ–°æ‚¨çš„å…·é«”çŸ¥è­˜é»å¼±é»åˆ†æ...")
            for error in error_analysis:
                correct_phrase = error.get('correction')
                
                if exclude_phrase and correct_phrase == exclude_phrase:
                    print(f"  - (å¿½ç•¥å·²è™•ç†çš„è¤‡ç¿’é»: {exclude_phrase})")
                    continue
                
                category = error.get('error_type')
                subcategory = error.get('error_subtype')
                explanation = error.get('explanation')
                incorrect_phrase = error.get('original_phrase')
                summary = error.get('key_point_summary', 'æ ¸å¿ƒè§€å¿µ') # æ–°å¢ï¼Œä¸¦æä¾›é è¨­å€¼
                
                if not category or not subcategory or not correct_phrase:
                    continue

                cursor.execute("SELECT id, mastery_level FROM knowledge_points WHERE correct_phrase = %s", (correct_phrase,))
                point = cursor.fetchone()
                severity_penalty = 0.5 if error.get('severity') == 'major' else 0.2

                if point:
                    new_mastery_level = max(0, point[1] - severity_penalty)
                    cursor.execute(
                        """
                        UPDATE knowledge_points 
                        SET mistake_count = mistake_count + 1, mastery_level = %s, user_context_sentence = %s, incorrect_phrase_in_context = %s, key_point_summary = %s, last_reviewed_on = %s, next_review_date = %s
                        WHERE id = %s
                        """,
                        (new_mastery_level, user_answer, incorrect_phrase, summary, datetime.datetime.now(datetime.timezone.utc), datetime.date.today() + datetime.timedelta(days=1), point[0])
                    )
                    print(f"  - å·²æ›´æ–°å¼±é»ï¼š[{summary}]ï¼Œç†Ÿç·´åº¦ä¸‹é™ã€‚")
                else:
                    cursor.execute(
                        """
                        INSERT INTO knowledge_points (category, subcategory, correct_phrase, explanation, user_context_sentence, incorrect_phrase_in_context, key_point_summary, mistake_count, mastery_level, last_reviewed_on, next_review_date)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, 1, 0.0, %s, %s)
                        """,
                        (category, subcategory, correct_phrase, explanation, user_answer, incorrect_phrase, summary, datetime.datetime.now(datetime.timezone.utc), datetime.date.today() + datetime.timedelta(days=1))
                    )
                    print(f"  - å·²ç™¼ç¾æ–°å¼±é»ï¼š[{summary}]ï¼Œå·²åŠ å…¥è¤‡ç¿’è¨ˆç•«ã€‚")

    conn.commit()
    conn.close()

    if not is_correct:
        print(f"\n(æœ¬å¥ä¸»è¦éŒ¯èª¤å·²æ­¸æª”ï¼š{primary_error_category} - {primary_error_subcategory})")


# --- AI åŠŸèƒ½å‡½å¼ ---
try:
    client = openai.OpenAI()
except openai.OpenAIError:
    print("éŒ¯èª¤ï¼šOPENAI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®šæˆ–ç„¡æ•ˆã€‚")
    exit()

def generate_question_batch(weak_points_str, num_review):
    """
    (è¤‡ç¿’é¡Œ) æ­¤å‡½å¼é‚è¼¯ç¶­æŒä¸è®Šã€‚
    """
    system_prompt = f"""
            ä½ æ˜¯ä¸€ä½é ‚å°–çš„è‹±æ–‡æ•™å­¸å°ˆå®¶èˆ‡å‘½é¡Œè€…ï¼Œå°ˆé–€è¨­è¨ˆã€Œç²¾æº–æ‰“æ“Šã€çš„è¤‡ç¿’é¡Œã€‚ä½ çš„æ ¸å¿ƒä»»å‹™æ˜¯æ ¹æ“šä¸‹æ–¹ä¸€ä»½é—œæ–¼å­¸ç”Ÿçš„ã€Œå…·é«”çŸ¥è­˜é»å¼±é»å ±å‘Šã€ï¼Œç‚ºä»–é‡èº«æ‰“é€  {num_review} é¡Œç¿»è­¯è€ƒé¡Œã€‚

            **ä½ çš„æ ¸å¿ƒå·¥ä½œåŸå‰‡ï¼š**
            1.  **ç²¾æº–æ‰“æ“Š**ï¼šä½ å¿…é ˆä»”ç´°åˆ†æå ±å‘Šä¸­åˆ—å‡ºçš„æ¯ä¸€å€‹ã€Œæ­£ç¢ºç”¨æ³•ã€ã€‚ä½ çš„æ¯ä¸€é“é¡Œéƒ½å¿…é ˆåœç¹é€™å€‹ã€Œæ­£ç¢ºç”¨æ³•ã€ä¾†è¨­è¨ˆï¼Œç¢ºä¿å­¸ç”Ÿèƒ½åœ¨ä¸€ä¸ªå…¨æ–°çš„å¥å­ä¸­æ­£ç¢ºåœ°ä½¿ç”¨å®ƒã€‚
            2.  **æƒ…å¢ƒå‰µé€ **ï¼šä¸è¦åªæ»¿è¶³æ–¼æ›¿æ›å–®å­—ã€‚ä½ è¦å‰µé€ ä¸€å€‹å…¨æ–°çš„ã€è‡ªç„¶çš„ã€åˆä¹é‚è¼¯çš„ä¸­æ–‡æƒ…å¢ƒï¼Œä½¿å¾—ã€Œæ­£ç¢ºç”¨æ³•ã€æ˜¯é€™å€‹æƒ…å¢ƒä¸‹æœ€è²¼åˆ‡çš„ç¿»è­¯ã€‚
            3.  **çµ•å°ä¿å¯†**ï¼šåœ¨ä½ çš„é¡Œç›®ä¸­ï¼Œçµ•å°ä¸èƒ½å‡ºç¾ã€Œæ­£ç¢ºç”¨æ³•ã€çš„ä»»ä½•è‹±æ–‡å­—çœ¼ã€‚ä½ çš„ä»»å‹™æ˜¯æä¾›ä¸­æ–‡æƒ…å¢ƒï¼Œè®“å­¸ç”Ÿè‡ªå·±æŠŠæ­£ç¢ºçš„è‹±æ–‡ç¿»è­¯å‡ºä¾†ã€‚
            4.  **ã€é‡è¦æŒ‡ä»¤ã€‘è¼¸å‡ºæ ¼å¼**ï¼šä½ å¿…é ˆåš´æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¼¸å‡ºã€‚åœ¨ JSON çš„ `new_sentence` æ¬„ä½ä¸­ï¼Œ**å¿…é ˆã€ä¸”åªèƒ½å¡«å…¥ä½ è¨­è¨ˆçš„ã€ä¸­æ–‡ã€‘è€ƒé¡Œå¥å­**ã€‚

            ç¯„ä¾‹æ ¼å¼:
            {{
                "questions": [
                    {{ "new_sentence": "é€™ä»½å·¥ä½œè–ªæ°´å¾ˆé«˜ï¼Œä½†å¦ä¸€æ–¹é¢ï¼Œå®ƒéœ€è¦ç¶“å¸¸åŠ ç­ã€‚" }}
                ]
            }}
            """
    user_prompt = f"""
        **ã€å­¸ç”Ÿå…·é«”çŸ¥è­˜é»å¼±é»å ±å‘Šã€‘**
        {weak_points_str}
        ---
        è«‹æ ¹æ“šä»¥ä¸Šå ±å‘Šï¼Œç‚ºæˆ‘ç”Ÿæˆ {num_review} é¡Œèƒ½æ¸¬é©—å‡ºå­¸ç”Ÿæ˜¯å¦å·²ç¶“æŒæ¡é€™äº›ã€Œæ­£ç¢ºç”¨æ³•ã€çš„ç¿»è­¯é¡Œã€‚
        è«‹å‹™å¿…è¨˜å¾—ï¼Œåœ¨è¼¸å‡ºçš„ JSON ä¸­ï¼Œ`new_sentence` æ¬„ä½çš„å€¼å¿…é ˆæ˜¯ä¸­æ–‡å¥å­ã€‚
        """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"}
        )
        response_data = json.loads(response.choices[0].message.content)
        questions_list = []
        if isinstance(response_data, dict):
            for value in response_data.values():
                if isinstance(value, list):
                    questions_list = value
                    break
        elif isinstance(response_data, list):
            questions_list = response_data
        return questions_list
    except Exception as e:
        print(f"AI å‚™èª²æ™‚ç™¼ç”ŸéŒ¯èª¤ (æœ‰è¤‡ç¿’é¡Œ): {e}")
        return None

# ä½æ–¼ main.py

def generate_new_question_batch(num_new, difficulty, length):
    """
    ã€v5.9.1 ä¿®æ­£ç‰ˆã€‘: åœ¨ Prompt ä¸­åŠ å…¥å° question ç‰©ä»¶å…§éƒ¨çµæ§‹çš„åš´æ ¼è¦å®šã€‚
    """
    # ... (æ–‡æ³•æ›¸å–æ¨£ã€ä¾‹å¥é¸å–çš„é‚è¼¯ç¶­æŒä¸è®Š) ...
    try:
        patterns_list = [p.strip() for p in translation_patterns.split('* ') if p.strip()]
        num_to_sample = min(len(patterns_list), 15)
        sampled_patterns = random.sample(patterns_list, num_to_sample)
        sampled_patterns_str = "* " + "\n* ".join(sampled_patterns)
    except Exception as e:
        print(f"æ–‡æ³•æ›¸å–æ¨£å¤±æ•—: {e}")
        sampled_patterns_str = "ï¼ˆæ–‡æ³•æ›¸å–æ¨£å¤±æ•—ï¼‰"

    example_sentences = EXAMPLE_SENTENCE_BANK.get(length, EXAMPLE_SENTENCE_BANK['medium']) \
                                             .get(str(difficulty), EXAMPLE_SENTENCE_BANK['medium']['3'])
    example_sentences_str = "\n".join([f"- {s}" for s in example_sentences])

    # ã€æ ¸å¿ƒä¿®æ”¹è™•ã€‘: æ”¹é€ æŒ‡ä»¤ä¸‰ï¼ŒåŠ å…¥è©³ç´°çš„ç‰©ä»¶çµæ§‹èªªæ˜å’Œç¯„ä¾‹
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½è¶…ç´šé«˜æ•ˆçš„è‹±æ–‡å‘½é¡Œ AIã€‚ä½ çš„ä»»å‹™æ˜¯åš´æ ¼éµå¾ªä»¥ä¸‹ä¸‰é …æŒ‡ä»¤ï¼Œç‚ºæˆ‘ç”Ÿæˆ {num_new} é¡Œç¿»è­¯è€ƒé¡Œã€‚

    **æŒ‡ä»¤ä¸€ï¼šæ¨¡ä»¿é¢¨æ ¼**
    ä½ å¿…é ˆæ·±åº¦å­¸ç¿’ä¸‹æ–¹çš„ã€Œé¢¨æ ¼åƒè€ƒç¯„ä¾‹ã€ï¼Œä½ çš„å‡ºé¡Œç”¨å­—ã€å¥å¼è¤‡é›œåº¦å’Œä¸»é¡Œï¼Œéƒ½å¿…é ˆèˆ‡é€™äº›ç¯„ä¾‹çš„é¢¨æ ¼å®Œå…¨ä¸€è‡´ã€‚
    ---
    ã€é¢¨æ ¼åƒè€ƒç¯„ä¾‹ (ä¾†è‡ªé›£åº¦ {difficulty} / é•·åº¦ {length})ã€‘
    {example_sentences_str}
    ---

    **æŒ‡ä»¤äºŒï¼šé‹ç”¨å¥å‹**
    åœ¨å‡ºé¡Œæ™‚ï¼Œä½ å¿…é ˆå¾ä¸‹æ–¹çš„ã€ŒæŒ‡å®šå¥å‹åº«ã€ä¸­ï¼Œé¸æ“‡åˆé©çš„å¥å‹èå…¥åˆ°ä½ çš„é¡Œç›®è£¡ã€‚
    ---
    ã€æŒ‡å®šå¥å‹åº« (æœ¬æ¬¡éš¨æ©ŸæŠ½å–)ã€‘
    {sampled_patterns_str}
    ---

    **æŒ‡ä»¤ä¸‰ï¼šåš´æ ¼è¼¸å‡º**
    ä½ å¿…é ˆåš´æ ¼å›å‚³ä¸€å€‹ JSON ç‰©ä»¶ã€‚æ­¤ç‰©ä»¶çš„æ ¹éƒ¨å¿…é ˆæœ‰ä¸€å€‹åç‚º "questions" çš„ keyï¼Œå…¶ value æ˜¯ä¸€å€‹åŒ…å« {num_new} å€‹å•é¡Œç‰©ä»¶çš„åˆ—è¡¨ã€‚
    **æ¯ä¸€å€‹å•é¡Œç‰©ä»¶éƒ½å¿…é ˆã€ä¸”åªèƒ½åŒ…å«ä¸€å€‹ keyï¼Œåç‚º "new_sentence"**ï¼Œå…¶ value ç‚ºä½ è¨­è¨ˆçš„ä¸­æ–‡è€ƒé¡Œã€‚

    ç¯„ä¾‹æ ¼å¼ï¼š
    {{
        "questions": [
            {{ "new_sentence": "ä¸­æ–‡è€ƒé¡Œä¸€..." }},
            {{ "new_sentence": "ä¸­æ–‡è€ƒé¡ŒäºŒ..." }}
        ]
    }}
    """
    user_prompt = f"è«‹åš´æ ¼éµç…§ä½ çš„ä¸‰é …æ ¸å¿ƒæŒ‡ä»¤ï¼Œç‚ºæˆ‘ç”Ÿæˆ {num_new} é¡Œè€ƒé¡Œã€‚"

    # ... (å¾ŒçºŒçš„ MONITOR_MODE å’Œ try/except é‚è¼¯ç¶­æŒä¸è®Š) ...
    if MONITOR_MODE:
        print("\n" + "="*20 + " AI å‚™èª² (Token å„ªåŒ–ç‰ˆ v2) INPUT " + "="*20)
        print("--- SYSTEM PROMPT ---")
        print(system_prompt)
        print("\n--- USER PROMPT ---")
        print(user_prompt)
        print("="*75 + "\n")
        
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"}
        )
        response_data = json.loads(response.choices[0].message.content)
        questions_list = []
        if isinstance(response_data, dict):
            for value in response_data.values():
                if isinstance(value, list):
                    questions_list = value
                    break
        elif isinstance(response_data, list):
            questions_list = response_data
        
        return questions_list
    except Exception as e:
        print(f"AI å‚™èª²æ™‚ç™¼ç”ŸéŒ¯èª¤ (Token å„ªåŒ–ç‰ˆ): {e}")
        return None
    
def get_tutor_feedback(chinese_sentence, user_translation, review_context=None):
    """
    ã€v5.13 æœ€çµ‚æ”¹é€ ã€‘: å¼•å…¥ã€ŒéŒ¯èª¤ç„¦é»ã€æ¦‚å¿µï¼Œé€éå¤§é‡ç¯„ä¾‹ï¼ŒæŒ‡å° AI ç”Ÿæˆæ¥µåº¦ç²¾ç°¡çš„è¦é»ã€‚
    """
    
    # å…±åŒçš„æŒ‡ä»¤éƒ¨åˆ†ï¼Œå®šç¾©äº† error_analysis çš„çµæ§‹å’Œ key_point_summary çš„ç”Ÿæˆè¦å‰‡
    error_analysis_instructions = """
    4.  `error_analysis`: (array of objects) ä¸€å€‹æ¸…å–®ï¼Œå¦‚æœæ²’æœ‰ä»»ä½•éŒ¯èª¤ï¼Œè«‹å›å‚³ä¸€å€‹ç©ºæ¸…å–® `[]`ã€‚
        æ¸…å–®ä¸­çš„æ¯ä¸€å€‹ç‰©ä»¶éƒ½å¿…é ˆåŒ…å«ä»¥ä¸‹æ‰€æœ‰æ¬„ä½ï¼š
        * `key_point_summary`: (string) ã€æœ€é‡è¦çš„æ¬„ä½ã€‘è«‹ç‚ºé€™å€‹éŒ¯èª¤é»æç…‰ä¸€å€‹ã€ŒéŒ¯èª¤ç„¦é»ã€ã€‚é€™ä¸æ˜¯ä¸€å€‹æ™®é€šçš„æ¨™é¡Œï¼Œè€Œæ˜¯ä¸€å€‹èƒ½è®“å­¸ç”Ÿç«‹åˆ»å›æ†¶èµ·éŒ¯èª¤çš„ã€ç²¾ç°¡çš„æç¤ºã€‚è«‹åš´æ ¼æ¨¡ä»¿ä¸‹æ–¹çš„ç¯„ä¾‹æ ¼å¼ï¼š
            - å¦‚æœæ˜¯ä»‹ç³»è©éŒ¯èª¤ï¼Œç¯„ä¾‹ï¼š`"on" the other hand`
            - å¦‚æœæ˜¯å‹•è©æ™‚æ…‹/å½¢å¼éŒ¯èª¤ï¼Œç¯„ä¾‹ï¼š`strive "to V"` æˆ– `be used "to V-ing"`
            - å¦‚æœæ˜¯ç‰¹å®šæ–‡æ³•çµæ§‹ï¼Œç¯„ä¾‹ï¼š`å¼·èª¿å¥æ§‹ (It is... that...)`
            - å¦‚æœæ˜¯å–®å­—æ‹¼å¯«éŒ¯èª¤ï¼Œç¯„ä¾‹ï¼š`"tomorrow" (æ‹¼å¯«)`
        * `error_type`: (string) `æ–‡æ³•éŒ¯èª¤`, `å–®å­—é¸æ“‡`, `æ…£ç”¨èªä¸ç†Ÿ`, `èªæ°£ä¸ç•¶`, `å¥æ§‹å•é¡Œ`, `æ‹¼å¯«éŒ¯èª¤`, `è´…å­—æˆ–æ¼å­—`ã€‚
        * `error_subtype`: (string) 2-5 å€‹å­—çš„å°ˆæ¥­è¡“èªã€‚
        * `original_phrase`: (string) å¾å­¸ç”Ÿç­”æ¡ˆä¸­ï¼Œç²¾ç¢ºåœ°æå–å‡ºéŒ¯èª¤çš„é‚£å€‹å–®å­—æˆ–ç‰‡èªã€‚
        * `correction`: (string) é‡å°è©²éŒ¯èª¤ç‰‡èªï¼Œæä¾›æ­£ç¢ºçš„å¯«æ³•ã€‚
        * `explanation`: (string) ç°¡æ½”åœ°è§£é‡‹ç‚ºä»€éº¼é€™æ˜¯éŒ¯çš„ã€‚
        * `severity`: (string) `major` æˆ– `minor`ã€‚
    """

    if review_context:
        # é€™æ˜¯è¤‡ç¿’é¡Œçš„ã€Œç›®æ¨™å°å‘ã€prompt
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½é ‚å°–çš„è‹±æ–‡æ•™å­¸å°ˆå®¶ï¼Œæ­£åœ¨ç‚ºä¸€åå­¸ç”Ÿé€²è¡Œã€Œæ ¸å¿ƒè§€å¿µã€çš„è¤‡ç¿’é©—æ”¶ã€‚

        **ä½ çš„é¦–è¦ä»»å‹™ï¼š**
        å­¸ç”Ÿçš„æœ¬æ¬¡ä½œç­”ï¼Œæ˜¯ç‚ºäº†æ¸¬é©—ä»–æ˜¯å¦å·²ç¶“æŒæ¡äº†ä»¥ä¸‹é€™å€‹æ ¸å¿ƒè§€å¿µï¼š
        - **æ ¸å¿ƒè¤‡ç¿’è§€å¿µ: "{review_context}"**

        è«‹åœ¨ä½ çš„ JSON å›è¦†ä¸­ï¼Œå‹™å¿…åŒ…å«ä¸€å€‹åç‚º `did_master_review_concept` çš„å¸ƒæ—å€¼æ¬„ä½ã€‚

        **ä½ çš„æ¬¡è¦ä»»å‹™ï¼š**
        åœ¨å®Œæˆé¦–è¦ä»»å‹™å¾Œï¼Œè«‹å°å­¸ç”Ÿçš„æ•´å€‹å¥å­é€²è¡Œå¸¸è¦çš„éŒ¯èª¤åˆ†æã€‚

        **ã€é‡è¦æŒ‡ä»¤ã€‘è¼¸å‡ºæ ¼å¼**
        ä½ çš„ JSON å›è¦†å¿…é ˆåŒ…å«ä»¥ä¸‹æ‰€æœ‰æ¬„ä½ï¼š
        1.  `did_master_review_concept`: (boolean) å­¸ç”Ÿæ˜¯å¦æŒæ¡äº†æœ¬æ¬¡çš„æ ¸å¿ƒè¤‡ç¿’è§€å¿µã€‚
        2.  `is_generally_correct`: (boolean) ç¶œåˆåˆ¤æ–·ï¼Œå­¸ç”Ÿçš„å¥å­æ•´é«”æ˜¯å¦å¤§è‡´æ­£ç¢ºã€‚
        3.  `overall_suggestion`: (string) æä¾›æ•´é«”æœ€æµæš¢çš„ç¿»è­¯å»ºè­°ã€‚
        {error_analysis_instructions}

        **åŸå§‹ä¸­æ–‡å¥å­æ˜¯**ï¼š"{chinese_sentence}"
        """
    else:
        # é€™æ˜¯æ–°é¡Œç›®çš„å¸¸è¦ prompt
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½æ¥µå…¶ç´°å¿ƒã€å°ˆæ¥­ä¸”æœ‰è€å¿ƒçš„è‹±æ–‡å®¶æ•™ã€‚ä½ çš„ä»»å‹™æ˜¯åƒæ‰¹æ”¹ä½œæ¥­ä¸€æ¨£ï¼Œé€å­—é€å¥åˆ†æå­¸ç”Ÿå¾ä¸­æ–‡ç¿»è­¯åˆ°è‹±æ–‡çš„ç­”æ¡ˆï¼Œä¸¦å›å‚³ä¸€ä»½çµæ§‹åŒ–çš„ JSON åˆ†æå ±å‘Šã€‚

        **ã€é‡è¦æŒ‡ä»¤ã€‘è¼¸å‡ºæ ¼å¼**
        ä½ å¿…é ˆåš´æ ¼å›å‚³ä¸€å€‹ JSON ç‰©ä»¶ï¼Œçµ•å°ä¸èƒ½åŒ…å« JSON æ ¼å¼ä»¥å¤–çš„ä»»ä½•æ–‡å­—ã€‚æ­¤ JSON ç‰©ä»¶å¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
        1.  `is_generally_correct`: (boolean)
        2.  `overall_suggestion`: (string)
        3.  `error_analysis`: (array of objects)
        {error_analysis_instructions}

        **åŸå§‹ä¸­æ–‡å¥å­æ˜¯**ï¼š"{chinese_sentence}"
        """

    user_prompt = f"é€™æ˜¯æˆ‘çš„ç¿»è­¯ï¼šã€Œ{user_translation}ã€ã€‚è«‹æ ¹æ“šä½ çš„å°ˆæ¥­çŸ¥è­˜å’Œä¸Šè¿°æŒ‡ä»¤ï¼Œç‚ºæˆ‘ç”Ÿæˆä¸€ä»½é‰…ç´°é¡éºçš„ JSON åˆ†æå ±å‘Šã€‚"

    if MONITOR_MODE:
        print("\n" + "="*20 + " AI æ‰¹æ”¹ (v5.13) INPUT " + "="*20)
        print("--- SYSTEM PROMPT ---")
        print(system_prompt)
        print("\n--- USER PROMPT ---")
        print(user_prompt)
        print("="*65 + "\n")

    try:
        response = client.chat.completions.create(
            model="gpt-4o", # ä½¿ç”¨èƒ½åŠ›æ›´å¼·çš„æ¨¡å‹ä¾†ç†è§£å’Œéµå¾ªè¤‡é›œçš„æ ¼å¼æŒ‡ä»¤
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"}
        )
        feedback_data = json.loads(response.choices[0].message.content)
        return feedback_data
    except Exception as e:
        print(f"AI æ‰¹æ”¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {
            "did_master_review_concept": False, "is_generally_correct": False, "overall_suggestion": "N/A",
            "error_analysis": [{"error_type": "ç³»çµ±éŒ¯èª¤", "explanation": f"ç³»çµ±ç„¡æ³•è™•ç† AI çš„å›è¦†ï¼š{e}"}]
        }

def update_knowledge_point_mastery(point_id, current_mastery):
    """
    ã€v5.4 PostgreSQL ç‰ˆã€‘: æ›´æ–°ç­”å°çš„çŸ¥è­˜é»ç†Ÿç·´åº¦ã€‚
    """
    new_mastery_level = min(5.0, current_mastery + 0.25)
    interval_days = max(1, round(2 ** new_mastery_level))
    next_review_date = datetime.date.today() + datetime.timedelta(days=interval_days)
    
    conn = get_db_connection()
    with conn.cursor() as cursor:
        cursor.execute(
            """
            UPDATE knowledge_points 
            SET mastery_level = %s, correct_count = correct_count + 1, next_review_date = %s 
            WHERE id = %s
            """,
            (new_mastery_level, next_review_date, point_id)
        )
    conn.commit()
    conn.close()
    print(f"(å¤ªæ£’äº†ï¼é€™å€‹è§€å¿µæˆ‘å€‘å®‰æ’åœ¨ {interval_days} å¤©å¾Œè¤‡ç¿’ã€‚)")

def get_due_knowledge_points(limit):
    """
    ã€v5.4 PostgreSQL ç‰ˆã€‘: ç²å–åˆ°æœŸä¸”æŒæ¡åº¦æœ€ä½çš„ã€ŒçŸ¥è­˜é»ã€ã€‚
    """
    conn = get_db_connection()
    # ä½¿ç”¨ DictCursor è®“å›å‚³çš„çµæœå¯ä»¥ç”¨æ¬„ä½åç¨±å­˜å–
    with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cursor:
        today = datetime.date.today()
        cursor.execute(
            """
            SELECT * FROM knowledge_points 
            WHERE next_review_date <= %s 
            ORDER BY mastery_level ASC, last_reviewed_on ASC
            LIMIT %s
            """,
            (today, limit)
        )
        points = cursor.fetchall()
    conn.close()
    return points

def start_dynamic_session():
    """
    æœ¬åœ°ç«¯æ¸¬è©¦ç”¨çš„å‡½å¼ã€‚
    """
    print(f"\n--- ğŸš€ æº–å‚™é–‹å§‹æ–°çš„ä¸€è¼ªå­¸ç¿’ (å…± {SESSION_SIZE} é¡Œ) ---")

    num_review_questions = int(SESSION_SIZE * REVIEW_RATIO)
    due_knowledge_points = get_due_knowledge_points(num_review_questions)
    actual_num_review = len(due_knowledge_points)
    num_new_questions = SESSION_SIZE - actual_num_review
    
    questions_to_ask = []
    print("AI è€å¸«æ­£åœ¨ç‚ºæ‚¨å‚™èª²ï¼Œè«‹ç¨å€™...")

    if actual_num_review > 0:
        weak_points_for_prompt = [
            f"- éŒ¯èª¤åˆ†é¡: {p['category']} -> {p['subcategory']}\n  æ­£ç¢ºç”¨æ³•: \"{p['correct_phrase']}\"\n  æ ¸å¿ƒè§€å¿µ: {p['explanation']}"
            for p in due_knowledge_points
        ]
        weak_points_str = "\n\n".join(weak_points_for_prompt)
        print(f"æ­£åœ¨é‡å°æ‚¨ä»¥ä¸‹çš„ {actual_num_review} å€‹å…·é«”å¼±é»è¨­è¨ˆè€ƒé¡Œï¼š\n{weak_points_str}")
        
        review_questions = generate_question_batch(weak_points_str, actual_num_review)
        if review_questions:
            for q, point in zip(review_questions, due_knowledge_points):
                if isinstance(q, dict):
                    q['type'] = 'review'
                    q['knowledge_point_id'] = point['id']
                    q['mastery_level'] = point['mastery_level']
            questions_to_ask.extend(review_questions)

    if num_new_questions > 0:
        print(f"æ­£åœ¨ç‚ºæ‚¨æº–å‚™ {num_new_questions} å€‹å…¨æ–°æŒ‘æˆ°...")
        # ã€ä¿®æ”¹ã€‘ç‚ºäº†è®“æœ¬åœ°æ¸¬è©¦èƒ½é †åˆ©é‹è¡Œï¼Œæ­¤è™•æä¾›ä¸€çµ„é è¨­çš„é›£åº¦å’Œé•·åº¦åƒæ•¸
        new_questions = generate_new_question_batch(num_new_questions, difficulty=3, length='medium')
        if new_questions:
            for q in new_questions:
                if isinstance(q, dict):
                    q['type'] = 'new'
            questions_to_ask.extend(new_questions)
    
    if not questions_to_ask:
        print("AI å‚™èª²å¤±æ•—æˆ–ç„¡é¡Œç›®å¯å­¸ï¼Œç„¡æ³•é–‹å§‹æœ¬è¼ªç·´ç¿’ã€‚")
        return
        
    random.shuffle(questions_to_ask)
    print("\nAI è€å¸«å·²å‚™èª²å®Œæˆï¼æº–å‚™å¥½äº†å—ï¼Ÿ")
    input("æŒ‰ Enter éµé–‹å§‹ä¸Šèª²...")

    for i, question_data in enumerate(questions_to_ask, 1):
        print(f"\n--- ç¬¬ {i}/{len(questions_to_ask)} é¡Œ ({question_data.get('type', 'æœªçŸ¥')}é¡å‹) ---")
        sentence = question_data.get('new_sentence', 'ï¼ˆé¡Œç›®ç²å–å¤±æ•—ï¼‰')
        print(f"è«‹ç¿»è­¯ï¼š{sentence}")
        
        user_answer = input("ä½ çš„ç¿»è­¯: ")
        if user_answer.strip().lower() == 'exit':
            print("\nå·²æå‰çµæŸæœ¬è¼ªç·´ç¿’ã€‚")
            return
            
        feedback_data = get_tutor_feedback(sentence, user_answer)
        print("\n--- ğŸ“ å®¶æ•™é»è©• ---")
        print(f"æ•´é«”å»ºè­°ç¿»è­¯ï¼š{feedback_data.get('overall_suggestion', 'ç„¡æ³•ç²å–å»ºè­°ç¿»è­¯ã€‚')}")

        add_mistake(question_data, user_answer, feedback_data)
        
        if question_data.get('type') == 'review' and feedback_data.get('is_generally_correct'):
            point_id = question_data.get('knowledge_point_id')
            mastery = question_data.get('mastery_level')
            if point_id is not None and mastery is not None:
                update_knowledge_point_mastery(point_id, mastery)

        if i < len(questions_to_ask):
            input("\næŒ‰ Enter éµç¹¼çºŒä¸‹ä¸€é¡Œ...")

    print("\n--- ğŸ‰ æ­å–œï¼å®Œæˆäº†æœ¬è¼ªæ‰€æœ‰ç·´ç¿’ï¼ ---")

def main():
    """
    ä¸»åŸ·è¡Œå‡½å¼ï¼Œç”¨æ–¼æœ¬åœ°ç«¯æ¸¬è©¦ã€‚
    """
    if DATABASE_URL:
        init_db()
    else:
        print("éŒ¯èª¤ï¼šæœªè¨­å®š DATABASE_URL ç’°å¢ƒè®Šæ•¸ï¼Œç„¡æ³•å•Ÿå‹•ã€‚")
        return

    while True:
        print("\n--- ğŸŒŸ å‹•æ…‹ AI è‹±æ–‡å®¶æ•™ (v5.9) ğŸŒŸ ---")
        print("1. é–‹å§‹ä¸€è¼ªæ™ºæ…§å­¸ç¿’ (æœ¬åœ°æ¸¬è©¦)")
        print("2. çµæŸç¨‹å¼")
        choice = input("è«‹è¼¸å…¥ä½ çš„é¸æ“‡ (1/2): ")

        if choice == '1':
            start_dynamic_session()
        elif choice == '2':
            print("\næ°æ°ï¼Œä¸‹æ¬¡è¦‹ï¼ğŸ‘‹")
            break
        else:
            print("\nç„¡æ•ˆçš„è¼¸å…¥ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")


def get_daily_activity(year, month):
    """
    ã€v5.11 æ–°å¢ã€‘: æŸ¥è©¢ç‰¹å®šæœˆä»½çš„æ¯æ—¥å­¸ç¿’æ´»å‹•æ•¸é‡ã€‚
    """
    conn = get_db_connection()
    # ä½¿ç”¨ DictCursor è®“å›å‚³çš„çµæœå¯ä»¥ç”¨æ¬„ä½åç¨±å­˜å–
    with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cursor:
        # ä½¿ç”¨ PostgreSQL çš„ date_trunc å‡½å¼ä¾†æŒ‰å¤©åˆ†çµ„ï¼Œä¸¦è¨ˆç®—æ¯å¤©çš„ç´€éŒ„æ•¸é‡
        # TIMESTAMPTZ 'epoch' å¯ä»¥å°‡æ™‚é–“æˆ³è½‰æ›ç‚º Unix æ™‚é–“ï¼Œæ–¹ä¾¿è™•ç†
        # æˆ‘å€‘åªæŸ¥è©¢ 'timestamp' æ¬„ä½ï¼Œä¸¦å°‡å…¶è½‰æ›ç‚ºä¼ºæœå™¨æ‰€åœ¨æ™‚å€çš„æ—¥æœŸ
        query = """
        SELECT
            DATE_TRUNC('day', timestamp AT TIME ZONE 'UTC')::date AS activity_date,
            COUNT(id) AS activity_count
        FROM
            learning_events
        WHERE
            EXTRACT(YEAR FROM timestamp AT TIME ZONE 'UTC') = %s AND
            EXTRACT(MONTH FROM timestamp AT TIME ZONE 'UTC') = %s
        GROUP BY
            activity_date
        ORDER BY
            activity_date;
        """
        cursor.execute(query, (year, month))
        activities = cursor.fetchall()
    conn.close()
    
    # å°‡æŸ¥è©¢çµæœè½‰æ›ç‚º App æ›´æ˜“æ–¼ä½¿ç”¨çš„ { "YYYY-MM-DD": count } æ ¼å¼
    heatmap_data = {activity['activity_date'].isoformat(): activity['activity_count'] for activity in activities}
    return heatmap_data

if __name__ == '__main__':
    main()